{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import os, h5py\n",
    "from pathlib import Path\n",
    "import time\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import datashade\n",
    "from holoviews.streams import PlotSize\n",
    "import datashader as ds\n",
    "import datashader.transfer_functions as tf\n",
    "\n",
    "PlotSize.scale=2\n",
    "hv.extension('plotly', 'bokeh', 'matplotlib')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Use Dummy hdf to get error over time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath to hdf file\n",
    "modelHDF_path = Path(r'C:\\Users\\christianl\\repos\\WF_Analysis\\read_hdf\\WF_WestForkCalcasieu.p05.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates variable of hdf file that will be read\n",
    "hdfFile = h5py.File(modelHDF_path,'r')\n",
    "\n",
    "# sets path within hdf file to find simulation window\n",
    "hdfplan_general = hdfFile['Plan Data']['Plan Information'].attrs\n",
    "\n",
    "# converts plan infomration to pandas series\n",
    "# planDatageneral = pd.Series(hdfplan_general).map(lambda st: st.decode('UTF-8'))\n",
    "# this will not work for models run with adjusted time step\n",
    "# this will convert paln info to pandas series and decode b strings while skiping integers and floats and shit \n",
    "planDatageneral = pd.Series(hdfplan_general).map(lambda x: x.decode('UTF-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "\n",
    "# sets path within hdf file to find geometry information\n",
    "hdfpaln_geometryData = hdfFile['Geometry']['2D Flow Areas']['Attributes']\n",
    "\n",
    "# converts 2D Flow Area Information to dataframe\n",
    "planDataGeometry = np.array(hdfpaln_geometryData)\n",
    "planDataGeometry = pd.DataFrame(planDataGeometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planDatageneral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(planDataGeometry['Cell Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"picks\" the 2D Area name out of the geometry data\n",
    "geometry_2DName = str(planDataGeometry['Name'][0]).split(\"'\")[1]\n",
    "geometry_2DName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfplan_ComputeMessage = hdfFile['Results']['Summary']['Compute Messages (text)']\n",
    "plan_ComputeMessage = pd.Series(hdfplan_ComputeMessage).map(lambda x: x.decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plan_ComputeMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets path within hdf file to find the computed timestamps and timesteps in the computation block\n",
    "hdfplan_OutTimeDateStamp = hdfFile['Results']['Unsteady']['Output']['Output Blocks']['Computation Block']['Global']['Time Date Stamp (ms)']\n",
    "hdfplan_OutTimeDateStep = hdfFile['Results']['Unsteady']['Output']['Output Blocks']['DSS Hydrograph Output']['Unsteady Time Series']['Time Step']\n",
    "\n",
    "# converts plan infomration to pandas dataframe\n",
    "planDataOutTimeDateStamp = pd.Series(hdfplan_OutTimeDateStamp).map(lambda x: x.decode('ascii'))\n",
    "planDataOutTimeDateStep = pd.DataFrame(hdfplan_OutTimeDateStep, columns=['Seconds'])\n",
    "\n",
    "# convert decoded series to dataframe\n",
    "planDataOutTimeDateStamp_df = planDataOutTimeDateStamp.to_frame()\n",
    "\n",
    "# converts HEC-RAS's SAS format to a normal fucking timestamp\n",
    "planDataOutTimeDateStamp_df[0] = pd.to_datetime(planDataOutTimeDateStamp_df[0], format= \"%d%b%Y %H:%M:%S:%f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planDataOutTimeDateStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# planDataOutTimeDateStamp_df['time Step (Computed)'] = planDataOutTimeDateStamp_df[0]\n",
    "timeDiff = [] \n",
    "for idx, row in planDataOutTimeDateStamp_df.iterrows():\n",
    "    try:\n",
    "        timeDiffComp = planDataOutTimeDateStamp_df[0][idx] - planDataOutTimeDateStamp_df[0][idx-1]\n",
    "        timeDiff.append(timeDiffComp)\n",
    "    except:\n",
    "        timeDiffComp = 0\n",
    "        timeDiff.append(timeDiffComp)\n",
    "planDataOutTimeDateStamp_df['Time Step'] = pd.Series(timeDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planDataOutTimeDateStamp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets path within hdf file to find the 2D Iterations and 2D Itteration Error\n",
    "hdfplan_Out2DItterError = hdfFile['Results']['Unsteady']['Output']['Output Blocks']['Computation Block']['2D Global']['2D Iteration Error']\n",
    "hdfplan_Out2DItter = hdfFile['Results']['Unsteady']['Output']['Output Blocks']['Computation Block']['2D Global']['2D Iterations']\n",
    "\n",
    "# converts plan infomration to pandas dataframe\n",
    "planDataOut2DItterError = pd.DataFrame(hdfplan_Out2DItterError, columns=['Error'])\n",
    "planDataOut2DItter = pd.DataFrame(hdfplan_Out2DItter, columns=['Iterations', 'Random Boolean', 'Cell'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planDataOut2DItterError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeAnalysis_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeAnalysis_df['Time Stamp'] = planDataOutTimeDateStamp_df[0]\n",
    "runtimeAnalysis_df['Time Step'] = planDataOutTimeDateStamp_df['Time Step']\n",
    "runtimeAnalysis_df['Iterations'] = planDataOut2DItter['Iterations']\n",
    "runtimeAnalysis_df['Error'] = planDataOut2DItterError['Error']\n",
    "runtimeAnalysis_df['Cell'] = planDataOut2DItter['Cell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set cells marked as -1 to null\n",
    "runtimeAnalysis_df['Cell'].loc[runtimeAnalysis_df['Cell'] < 0 ] = np.nan\n",
    "\n",
    "# set zero error cells to null\n",
    "runtimeAnalysis_df['Error'].loc[runtimeAnalysis_df['Error'] == 0 ] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimeAnalysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputLocation=Path(r'../reports/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = runtimeAnalysis_df['Time Stamp']\n",
    "y = runtimeAnalysis_df['Error']\n",
    "fig = px.scatter(runtimeAnalysis_df, x=x, y=y, color='Iterations')\n",
    "fig.write_html(outputLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets path within hdf file to find cell locations\n",
    "hdfGeo_geoCellCenter = hdfFile['Geometry']['2D Flow Areas'][geometry_2DName]['Cells Center Coordinate']\n",
    "\n",
    "# creates dataframe from cell locations based on hdf file\n",
    "geoCellCenter=pd.DataFrame(np.array(hdfGeo_geoCellCenter))\n",
    "\n",
    "# renames columns to be easily identified\n",
    "geoCellCenter=geoCellCenter.rename(columns={0:'X',1:'Y'})\n",
    "\n",
    "# creates column with appropriate cell numbers\n",
    "geoCellCenter['Cell']=range(0,len(geoCellCenter))\n",
    "\n",
    "# creates geodataframe from dataframe using coordinates\n",
    "geoCellCenter=gpd.GeoDataFrame(geoCellCenter,geometry=gpd.points_from_xy(geoCellCenter.X,geoCellCenter.Y,crs='EPSG:6479'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets path within hdf file to find cell itteration data\n",
    "hdfResults_cellIterLook = hdfFile['Results']['Unsteady']['Output']['Output Blocks']['Base Output']['Summary Output']['2D Flow Areas'][geometry_2DName]['Cell Cumulative Iter Lookup']\n",
    "\n",
    "# creates dataframe from cell itterations\n",
    "cellIterLook = pd.DataFrame(np.array(hdfResults_cellIterLook),columns=['Cell','Iterations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellIterLook\n",
    "select_cellLookup = cellIterLook['Cell'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoCellIterLook = geoCellCenter[pd.DataFrame(geoCellCenter.Cell.tolist()).isin(select_cellLookup).any(1).values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoCellIterLook.explore()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## hdf File for Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:\\Users\\christianl\\repos\\WF_Analysis\\ras_runtimeDF.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets working directory\n",
    "pth=Path(r'C:\\Users\\christianl\\Documents\\WF_SensitivityAnalysis\\WF_WestForkCalcasieu')\n",
    "os.chdir(pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results files to be compared\n",
    "ctrl00_laura2020 = 'WF_WestForkCalcasieu.p06.hdf'\n",
    "gbrl40_laura2020 = 'WF_WestForkCalcasieu.p15.hdf'\n",
    "gbrl50_laura2020 = 'WF_WestForkCalcasieu.p07.hdf'\n",
    "gbrl50_10s_laura2020 = 'WF_WestForkCalcasieu.p10.hdf'\n",
    "gbrl50_30s_laura2020 = 'WF_WestForkCalcasieu.p11.hdf'\n",
    "gbrl50_60s_laura2020 = 'WF_WestForkCalcasieu.p12.hdf'\n",
    "gbrl50_120s_laura2020 = 'WF_WestForkCalcasieu.p13.hdf'\n",
    "filelist = [ctrl00_laura2020, gbrl40_laura2020, gbrl50_laura2020, gbrl50_10s_laura2020, gbrl50_30s_laura2020, gbrl50_60s_laura2020, gbrl50_120s_laura2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [generate_runtimeDF(file) for file in filelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\"ctrl00_laura2020\": df_list[0],\n",
    "\"gbrl40_laura2020\": df_list[1],\n",
    "\"gbrl50_laura2020\": df_list[2],\n",
    "\"gbrl50_10s_laura2020\": df_list[3],\n",
    "\"gbrl50_30s_laura2020\": df_list[4],\n",
    "\"gbrl50_60s_laura2020\": df_list[5],\n",
    "\"gbrl50_120s_laura2020\": df_list[6]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crete a dataframe with all the data with the name of the file as the column name in each row\n",
    "df = pd.concat(dfs,axis=0, keys=dfs.keys()).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "timeseries_df = datashade(hv.Scatter(df,kdims='Time Stamp',vdims=('Error', 'Error (%)'))).options(width=1000, height=500, title='Error vs Time Stamp', show_grid=True)\n",
    "timeseries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap = hv.HoloMap({file: hv.Scatter(dfs[file], kdims='Time Stamp', vdims=('Error', 'Error (%)')) for file in dfs.keys()}, kdims='File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap.opts(width=1000, height=500, title='Error vs Time Stamp', show_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.offline import iplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.scatter(x = df_list[1][\"Time Stamp\"], y= df_list[1][\"Error\"])\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.Figure()\n",
    "# for idx, obj in enumerate(df_list):\n",
    "#     fig = fig.add_trace(go.Scattergl(x = df_list[idx][\"Time Stamp\"],\n",
    "#                                    y = df_list[idx][\"Error\"],\n",
    "#                                    mode='markers'\n",
    "#                                    ))\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "from dash import Dash, dcc, html, Input, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs_keys = list(dfs.keys())\n",
    "# dfs_keys[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs.get('gbrl40_laura2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build App with \n",
    "# app = JupyterDash(__name__)\n",
    "# app.layout = html.Div([\n",
    "#     html.H1(\"JupyterDash Demo\"),\n",
    "#     dcc.Graph(id='graph'),\n",
    "#     html.Label([\n",
    "#         \"Input Variable\",\n",
    "#         dcc.Dropdown(\n",
    "#             # Build options from list of dataframes\n",
    "#             options=[{'label': k, 'value': k} for k in dfs.keys()],\n",
    "#             value='gbrl40_laura2020', id='df-dropdown')\n",
    "#     ]),\n",
    "#     html.Label([\n",
    "#         \"X Variable\",\n",
    "#         dcc.Dropdown(\n",
    "#             id='x-dropdown', clearable=False,\n",
    "#             value='Time Step', options=[\n",
    "#                 {'label': c, 'value': c}\n",
    "#                 for c in df_list[0].columns\n",
    "#             ])\n",
    "#     ]),\n",
    "#     html.Label([\n",
    "#         \"Y Variable\",\n",
    "#         dcc.Dropdown(\n",
    "#             id='y-dropdown', clearable=False,\n",
    "#             value='Error', options=[\n",
    "#                 {'label': c, 'value': c}\n",
    "#                 for c in df_list[0].columns\n",
    "#             ])]\n",
    "#         )\n",
    "\n",
    "# ])\n",
    "# # Define callback to update graph\n",
    "# @app.callback(\n",
    "#     Output('graph', 'figure'),\n",
    "#     [Input(\"df-dropdown\", \"value\"),\n",
    "#         Input(\"x-dropdown\", \"value\"),\n",
    "#         Input(\"y-dropdown\", \"value\")]\n",
    "# )\n",
    "# def update_figure(df, x, y):\n",
    "#     return px.scatter(\n",
    "#         dfs[df], x=x, y=y,\n",
    "#         render_mode=\"webgl\", title=\"Scatter Plot\"\n",
    "#     )\n",
    "# # Run app and display result eternal to the notebook\n",
    "# app.run_server(mode='external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import IFrame\n",
    "# documentation = IFrame(src='http://127.0.0.1:8050/', width=1000, height=500)\n",
    "# display(documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a Dash app within the JupyterDash server that shows the cell locations and the number of iterations\n",
    "# # for each cell in the model\n",
    "# app = JupyterDash(__name__)\n",
    "# app.layout = html.Div([\n",
    "#     html.H1(\"JupyterDash Demo\"),\n",
    "#     dcc.Graph(id='graph'),\n",
    "#     html.Label([\n",
    "#         \"Input Variable\",\n",
    "#         dcc.Dropdown(\n",
    "#             # Build options from list of dataframes with the cell number and the number of iterations\n",
    "#             options=[{'label': k, 'value': k} for k in dfs.keys()],\n",
    "#             value='gbrl40_laura2020', id='df-dropdown')\n",
    "#     ])\n",
    "# ])\n",
    "# # Define callback to update graph\n",
    "# @app.callback(\n",
    "#     Output('graph', 'figure'),\n",
    "#     [Input(\"df-dropdown\", \"value\")]\n",
    "# )\n",
    "# # create gespatial plot of cell locations and number of iterations\n",
    "# def update_figure(df):\n",
    "#     return px.scatter_geo(\n",
    "#         dfs[df], lat=\"Latitude\", lon=\"Longitude\", color=\"Iterations\",\n",
    "#         render_mode=\"webgl\", title=\"Scatter Plot\"\n",
    "#     )\n",
    "# # Run app and display result eternal to the notebook\n",
    "# app.run_server(mode='external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('WF_Analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f250576885a318bda0b61edaf1e18763d1ebb1c9e28f8ec91f7a38ddac81a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
